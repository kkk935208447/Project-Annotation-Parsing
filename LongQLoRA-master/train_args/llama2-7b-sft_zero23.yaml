# checkpoint 输出路径
output_dir: /workspace/output/llama2-7b-sft-zero

# model 路径
model_name_or_path: /workspace/Llama-2-7b-chat-hf

# 数据集路径
train_file: datas/paper_review_data_longqlora_10pct(第二版的数据).jsonl
# train_file: datas/paper_test.jsonl

# # deepspeed config  # accelerator 启动自带 deepspeed 插件, 故注释掉
# deepspeed: train_args/deepspeed/deepspeed_config_s3.json
# 是否使用sft
sft: true

# ++ 新增参数, trainer 断点续传, 也可以使用str
resume_from_checkpoint: true

# peft 适配器模型保存是否用  safetensors 格式
save_safetensors: false

# 模型参数
model_max_length: 16384  # PI 插值扩展
max_seq_length: 12288
# max_seq_length: 4096
  # ++, 新增參數, prompt 与 response 最大長度
max_prompt_length: 11651
# max_prompt_length: 3459
max_response_length: 637

# log
logging_steps: 2
log_level: info
  # 也可以使用 wandb
report_to: tensorboard

# 模型保存相关
save_strategy: steps
save_steps: 40
save_total_limit: 3

# TODO, 新增,模型 eval 相关
evaluation_strategy: steps
  # 每个4步进行验证
eval_steps: 40
  # 在训练结束时加载最优模型
load_best_model_at_end: true
  # 根据验证集的损失值选择最优模型
metric_for_best_model: "eval_loss"
  # 损失值越小越好
greater_is_better: false

# lora相关
lora_rank: 64
lora_alpha: 16
lora_dropout: 0.05

# ++ 新增, flash attention, 梯度检查点
# TODO 存在疑问: zero3 + flash + s2att 会backward报错, 其他组合没有问题, zero2 任何组合都正常运行
enable_s2attention: true
use_flash_attn: true
gradient_checkpointing: true
use_reentrant: true

# 优化器
lr_scheduler_type: constant_with_warmup
warmup_steps: 20
optim: paged_adamw_32bit

disable_tqdm: false

# 训练参数
learning_rate: 0.0001
num_train_epochs: 3
per_device_train_batch_size: 1
per_device_eval_batch_size: 4
gradient_accumulation_steps: 16
seed: 42
# fp16: true
bf16: true
dataloader_num_workers: 0
# weight_decay: 0.0
weight_decay: 0.001
max_grad_norm: 0.3
remove_unused_columns: false

# TODO 新增,bnb 4bit 相关参数
  # 是否双量化
use_nested_quant: true
  # 量化后计算类型
bnb_4bit_compute_dtype: bfloat16
  # 量化保存类型
bnb_4bit_quant_storage_dtype: bfloat16
  # 量化类型
bnb_4bit_quant_type: nf4