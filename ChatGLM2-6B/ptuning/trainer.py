# coding=utf-8
# Copyright 2020-present the HuggingFace Inc. team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
The Trainer class, to easily train a ğŸ¤— Transformers from scratch or finetune it on a new task.
è¿™ä¸ª Trainer ç±»çš„ç”¨é€”,å¯ä»¥è½»æ¾åœ°è®­ç»ƒæˆ–å¾®è°ƒä¸€ä¸ª Hugging Face Transformers æ¨¡å‹ã€‚
"""
import os
from typing import Optional
from transformers import Trainer

import torch
from transformers.modeling_utils import PreTrainedModel, unwrap_model
from transformers.utils import logging

logger = logging.get_logger(__name__)

WEIGHTS_NAME = "pytorch_model.bin"
TRAINING_ARGS_NAME = "training_args.bin"

# 1. å®šä¹‰ä¸€ä¸ªåä¸º PrefixTrainer çš„å­ç±»,ç»§æ‰¿è‡ª transformers.Trainer ç±»ã€‚
#    è¿™ä¸ªç±»ç”¨äºè®­ç»ƒå’Œå¾®è°ƒå…·æœ‰å‰ç¼€ç¼–ç çš„æ¨¡å‹ã€‚
class PrefixTrainer(Trainer):
    def __init__(self, *args, 
                 save_changed=False,  #    save_changed å‚æ•°ç”¨äºæ§åˆ¶æ˜¯å¦ä»…ä¿å­˜æ¨¡å‹çš„å‰ç¼€ç¼–ç éƒ¨åˆ†ã€‚
                 **kwargs):           #    *args å’Œ **kwargs ç”¨äºä¼ é€’ç»™çˆ¶ç±» Trainer çš„å…¶ä»–åˆå§‹åŒ–å‚æ•°ã€‚
        self.save_changed = save_changed
        super().__init__(*args, **kwargs)

    # é‡å†™çˆ¶ç±» Trainer ä¸­çš„ _save æ–¹æ³•,ä»¥å®ç°è‡ªå®šä¹‰çš„æ¨¡å‹ä¿å­˜ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•é‡å†™æœºåˆ¶å…è®¸å­ç±»é’ˆå¯¹ç‰¹å®šéœ€æ±‚,å¯¹çˆ¶ç±»æ–¹æ³•è¿›è¡Œç»†èŠ‚çº§åˆ«çš„å®šåˆ¶å’Œæ‰©å±•ã€‚
    def _save(self, output_dir: Optional[str] = None, 
              state_dict=None):
        
        # If we are executing this function, we are the process zero, so we don't check for that.
        output_dir = output_dir if output_dir is not None else self.args.output_dir

        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"Saving model checkpoint to {output_dir}")
        # Save a trained model and configuration using `save_pretrained()`.
        # They can then be reloaded using `from_pretrained()`
        if not isinstance(self.model, PreTrainedModel):
            if isinstance(unwrap_model(self.model), PreTrainedModel):
                if state_dict is None:
                    state_dict = self.model.state_dict()
                # ä½¿ç”¨ unwrap_model æå–å‡ºåº•å±‚çš„ PreTrainedModel å®ä¾‹
                # unwrap_model å‡½æ•°æ˜¯ transformers.modeling_utils æ¨¡å—ä¸­å®šä¹‰çš„ä¸€ä¸ªå·¥å…·å‡½æ•°,å®ƒçš„ä½œç”¨æ˜¯ä»ç»™å®šçš„æ¨¡å‹ä¸­æå–å‡ºåº•å±‚çš„ PreTrainedModel å®ä¾‹ã€‚
                # åœ¨ transformers æ¡†æ¶ä¸­,æ¨¡å‹å¯èƒ½è¢«åŒ…è£¹åœ¨å…¶ä»–å®¹å™¨ç±»ä¸­,æ¯”å¦‚ torch.nn.DataParallel æˆ– torch.nn.parallel.DistributedDataParallelã€‚è¿™äº›å®¹å™¨ç±»çš„ç›®çš„æ˜¯æ”¯æŒæ•°æ®å¹¶è¡Œè®­ç»ƒ,é€šè¿‡å°†æ¨¡å‹å¤åˆ¶åˆ°å¤šä¸ª GPU ä¸Šå¹¶è¡Œè¿è¡Œæ¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚
                # ä½†æ˜¯,å½“æˆ‘ä»¬éœ€è¦ä¿å­˜æ¨¡å‹æ—¶,æˆ‘ä»¬é€šå¸¸åªéœ€è¦ä¿å­˜åº•å±‚çš„ PreTrainedModel å®ä¾‹,è€Œä¸éœ€è¦ä¿å­˜è¿™äº›å®¹å™¨ç±»ã€‚unwrap_model å‡½æ•°å°±æ˜¯ç”¨æ¥ä»è¿™äº›å®¹å™¨ç±»ä¸­æå–å‡ºåº•å±‚çš„ PreTrainedModel å®ä¾‹çš„ã€‚
                # åœ¨ PrefixTrainer ç±»çš„ _save æ–¹æ³•ä¸­,æˆ‘ä»¬ä½¿ç”¨äº† unwrap_model å‡½æ•°æ¥å¤„ç†è¿™ç§æƒ…å†µ
                unwrap_model(self.model).save_pretrained(output_dir, state_dict=state_dict)
            else:
                logger.info("Trainer.model is not a `PreTrainedModel`, only saving its state dict.")
                if state_dict is None:
                    state_dict = self.model.state_dict()
                # è¿™é‡Œä¿å­˜æ—¶å‚æ•°
                torch.save(state_dict, os.path.join(output_dir, WEIGHTS_NAME))

        # 6. å¦‚æœæ¨¡å‹æ˜¯ PreTrainedModel çš„å®ä¾‹:
        #    å¦‚æœ self.save_changed ä¸º True,åˆ™ä»…ä¿å­˜å‰ç¼€ç¼–ç éƒ¨åˆ†;
        #    å¦åˆ™,ä¿å­˜æ•´ä¸ªæ¨¡å‹ã€‚
        #    è¿™ç§çµæ´»çš„ä¿å­˜ç­–ç•¥å¯ä»¥å¸®åŠ©ç”¨æˆ·æ ¹æ®å®é™…éœ€æ±‚è¿›è¡Œæƒè¡¡,åœ¨å­˜å‚¨ç©ºé—´å’Œæ¨¡å‹æ€§èƒ½ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚
        else:
            if self.save_changed:
                print("Saving PrefixEncoder")
                state_dict = self.model.state_dict()
                filtered_state_dict = {}
                for k, v in self.model.named_parameters():
                    if v.requires_grad:
                        filtered_state_dict[k] = state_dict[k]
                self.model.save_pretrained(output_dir, state_dict=filtered_state_dict)
            else:
                print("Saving the whole model")
                self.model.save_pretrained(output_dir, state_dict=state_dict)
         # 7. å¦‚æœå­˜åœ¨åˆ†è¯å™¨,åˆ™ä¿å­˜åˆ†è¯å™¨ã€‚
        #    è¿™ç¡®ä¿äº†æ¨¡å‹ä¸åˆ†è¯å™¨çš„ä¸€è‡´æ€§,ä¾¿äºåç»­ä½¿ç”¨ã€‚
        if self.tokenizer is not None:
            self.tokenizer.save_pretrained(output_dir)

        # Good practice: save your training arguments together with the trained model
        torch.save(self.args, os.path.join(output_dir, TRAINING_ARGS_NAME))
